{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, make_scorer, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import warnings\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 16\n",
    "nb_validation_samples = 16\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "\n",
    "# CNN specific preprocessing function, creating 4 dimensional input vectors\n",
    "def preprocess_cnn(n_samples, rescaled_dim, f_path =\"../data/train.csv\"):\n",
    "    df = pd.read_csv(f_path)\n",
    "    df['split_tags'] = df['tags'].map(lambda row: row.split(\" \"))\n",
    "    lb = MultiLabelBinarizer()\n",
    "    y = lb.fit_transform(df['split_tags'])\n",
    "    y = y[:n_samples]\n",
    "    \n",
    "    imgs = []\n",
    "    # for each image, rescale to same dimension and flattern\n",
    "    print \"processing images...\"\n",
    "    count = 0\n",
    "    for name in df.head(n_samples)['image_name'].values:\n",
    "        raw_img = plt.imread('../data/train-jpg/{}.jpg'.format(name))\n",
    "        #print raw_img\n",
    "        imgs.append(cv2.resize(raw_img, (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR)[:, :, :3])\n",
    "        count+=1\n",
    "        if count % 1000 == 0:\n",
    "            print count, \"processed\"\n",
    "\n",
    "    # remove dimenions, normalize  \n",
    "    X = np.squeeze(np.array(imgs)) / 255.\n",
    "\n",
    "    return np.array(X, np.float16), np.array(y, np.uint8), lb.classes_\n",
    "\n",
    "def optimize_threshold(X_test, y_test, model):\n",
    "    prediction = model.predict(X_test)\n",
    "    true_label = y_test\n",
    "    best_threshhold = [0.2]*17    \n",
    "    for t in range(17):\n",
    "        best_fbeta = 0\n",
    "        temp_threshhold = [0.2]*17\n",
    "        for i in range(100):\n",
    "            temp_value = i / float(100)\n",
    "            temp_threshhold[t] = temp_value\n",
    "            temp_fbeta = fbeta_score(true_label, prediction > temp_threshhold, beta=2, average=\"samples\")\n",
    "            if temp_fbeta > best_fbeta:\n",
    "                best_fbeta = temp_fbeta\n",
    "                best_threshhold[t] = temp_value\n",
    "    return best_threshhold\n",
    "\n",
    "\n",
    "# Using a trained model, calculate the F2_score\n",
    "# input: X_test, y_test, model\n",
    "# output: a list of F2_score by class(length 17)\n",
    "def calc_F2_score_cnn(X_test, y_test, model, thres = 0.2, avg_mode = None, opt = False):\n",
    "    if opt:\n",
    "        print \"Optimizing threshold...\"\n",
    "        thres = optimize_threshold(X_test, y_test, model)\n",
    "        print \"Using optimized threshold: \", thres\n",
    "    predicted = np.array(model.predict(X_test)) > thres\n",
    "    score = fbeta_score(y_test, predicted, beta=2, average=avg_mode)\n",
    "    return score\n",
    "\n",
    "def calc_precision_cnn(X_test, y_test, model, thres = 0.2, avg_mode = None, opt = False):\n",
    "    if opt:\n",
    "        print \"Optimizing threshold...\"\n",
    "        thres = optimize_threshold(X_test, y_test, model)\n",
    "        print \"Using optimized threshold: \", thres\n",
    "    predicted = np.array(model.predict(X_test)) > thres\n",
    "    score = precision_score(y_test, predicted, average=avg_mode)\n",
    "    return score\n",
    "\n",
    "def calc_recall_cnn(X_test, y_test, model, thres = 0.2, avg_mode = None, opt = False):\n",
    "    if opt:\n",
    "        print \"Optimizing threshold...\"\n",
    "        thres = optimize_threshold(X_test, y_test, model)\n",
    "        print \"Using optimized threshold: \", thres\n",
    "    predicted = np.array(model.predict(X_test)) > thres\n",
    "    score = recall_score(y_test, predicted, average=avg_mode)\n",
    "    return score\n",
    "\n",
    "def print_results(scores, ind_to_classes):\n",
    "    # print the scores with the classes\n",
    "    results = [(ind_to_classes[l], scores[l]) for l in scores.argsort()[::-1]]\n",
    "    print \"************************RESULTS************************\"\n",
    "    for res in results:\n",
    "        print res[0], res[1]\n",
    "    print \"************************END RESULTS************************\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(17, activation=\"sigmoid\")(x)\n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "model_final.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing images...\n",
      "1000 processed\n",
      "2000 processed\n",
      "3000 processed\n",
      "4000 processed\n",
      "5000 processed\n",
      "6000 processed\n",
      "7000 processed\n",
      "8000 processed\n",
      "9000 processed\n",
      "10000 processed\n",
      "11000 processed\n",
      "12000 processed\n",
      "13000 processed\n",
      "14000 processed\n",
      "15000 processed\n",
      "16000 processed\n",
      "17000 processed\n",
      "18000 processed\n",
      "19000 processed\n",
      "20000 processed\n",
      "21000 processed\n",
      "22000 processed\n",
      "23000 processed\n",
      "24000 processed\n",
      "25000 processed\n",
      "26000 processed\n",
      "27000 processed\n",
      "28000 processed\n",
      "29000 processed\n",
      "30000 processed\n",
      "31000 processed\n",
      "32000 processed\n",
      "33000 processed\n",
      "34000 processed\n",
      "35000 processed\n",
      "36000 processed\n",
      "37000 processed\n",
      "38000 processed\n",
      "39000 processed\n",
      "40000 processed\n",
      "(40479, 64, 64, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 40482\n",
    "NUM_SAMPLE = NUM_TRAIN\n",
    "DIM = 64\n",
    "X, y, ind_to_classes = preprocess_cnn(NUM_SAMPLE, DIM, \"../data/train.csv\")\n",
    "print X.shape, y.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "36431/36431 [==============================] - 1607s - loss: 0.1863 - acc: 0.9263  \n",
      "Epoch 2/5\n",
      "36431/36431 [==============================] - 1555s - loss: 0.1657 - acc: 0.9350  \n",
      "Epoch 3/5\n",
      "36431/36431 [==============================] - 1571s - loss: 0.1614 - acc: 0.9368  \n",
      "Epoch 4/5\n",
      "36431/36431 [==============================] - 1556s - loss: 0.1593 - acc: 0.9372  \n",
      "Epoch 5/5\n",
      "36431/36431 [==============================] - 1488s - loss: 0.1573 - acc: 0.9381  \n",
      "************************RESULTS************************\n",
      "primary 0.988106367508\n",
      "clear 0.956077630235\n",
      "cloudy 0.813106796117\n",
      "agriculture 0.808604287945\n",
      "partly_cloudy 0.795201582983\n",
      "road 0.73698515576\n",
      "haze 0.718673218673\n",
      "water 0.619625695498\n",
      "habitation 0.545410860163\n",
      "cultivation 0.493311036789\n",
      "artisinal_mine 0.434782608696\n",
      "bare_ground 0.028328611898\n",
      "slash_burn 0.0\n",
      "conventional_mine 0.0\n",
      "selective_logging 0.0\n",
      "blow_down 0.0\n",
      "blooming 0.0\n",
      "************************END RESULTS************************\n"
     ]
    }
   ],
   "source": [
    "model_final.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          verbose=1)\n",
    "scores = calc_F2_score_cnn(X_valid, y_valid, model_final)\n",
    "\n",
    "print_results(scores, ind_to_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model at a location\n",
    "import datetime\n",
    "def timestamp():\n",
    "    return '{:%m%d_%H_%M_%s}'.format(datetime.datetime.now())\n",
    "\n",
    "fn = \"../data/cnn-3_\" + timestamp() + '.h5'\n",
    "model_final.save(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing threshold...\n",
      "Using optimized threshold:  [0.28, 0.17, 0.14, 0.08, 0.06, 0.26, 0.17, 0.07, 0.24, 0.25, 0.21, 0.2, 0.3, 0.2, 0.09, 0.05, 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luda/cs231a-human-footprint/.env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86287071671215365"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_F2_score_cnn(X_valid, y_valid, model_final, thres = 0.2, avg_mode = \"samples\", opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_7\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_conv4\n",
      "11 block3_pool\n",
      "12 block4_conv1\n",
      "13 block4_conv2\n",
      "14 block4_conv3\n",
      "15 block4_conv4\n",
      "16 block4_pool\n",
      "17 block5_conv1\n",
      "18 block5_conv2\n",
      "19 block5_conv3\n",
      "20 block5_conv4\n",
      "21 block5_pool\n",
      "22 flatten_7\n",
      "23 dense_14\n",
      "24 dropout_7\n",
      "25 dense_15\n",
      "26 dense_16\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in enumerate(model_final.layers):\n",
    "    print idx, layer.name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on filters: [0]\n",
      "Working on filters: [1]"
     ]
    }
   ],
   "source": [
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_activation\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_name = 'dense_16'\n",
    "layer_idx = [idx for idx, layer in enumerate(model_final.layers) if layer.name == layer_name][0]\n",
    "\n",
    "# Generate three different images of the same output index.\n",
    "vis_images = []\n",
    "for idx in range(17):\n",
    "    img = visualize_activation(model_final, layer_idx, filter_indices=idx, max_iter=500)\n",
    "    #img = utils.draw_text(img, str(idx))\n",
    "    vis_images.append(img)\n",
    "\n",
    "stitched = utils.stitch_images(vis_images)    \n",
    "plt.axis('off')\n",
    "plt.imshow(stitched)\n",
    "plt.title(layer_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
