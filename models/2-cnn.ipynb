{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet model\n",
    "\n",
    "Building a simple ConvNet model for multi-label classification using Keras(Luda)\n",
    "\n",
    "Adapted from \"Simple Keras Starter\" Kernel from anokas on Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, precision_score, make_scorer, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import warnings\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General functions from 0-baseline notebook\n",
    "\n",
    "# Preprocess images\n",
    "# Input: number of samples, dim, path\n",
    "# Output: X, y, list of class names\n",
    "def preprocess(n_samples, rescaled_dim, f_path =\"../data/train.csv\"):\n",
    "    df = pd.read_csv(f_path)\n",
    "    df['split_tags'] = df['tags'].map(lambda row: row.split(\" \"))\n",
    "    lb = MultiLabelBinarizer()\n",
    "    y = lb.fit_transform(df['split_tags'])\n",
    "    y = y[:n_samples]\n",
    "    \n",
    "    imgs = []\n",
    "    # for each image, rescale to same dimension and flattern\n",
    "    print \"processing images...\"\n",
    "    count = 0\n",
    "    for name in df.head(n_samples)['image_name'].values:\n",
    "        raw_img = plt.imread('../data/train-jpg/{}.jpg'.format(name))\n",
    "        #print raw_img\n",
    "        imgs.append(cv2.resize(raw_img, (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR).reshape(1, -1))\n",
    "        count+=1\n",
    "        if count % 1000 == 0:\n",
    "            print count, \"processed\"\n",
    "\n",
    "    # remove dimenions    \n",
    "    X = np.squeeze(np.array(imgs))\n",
    "\n",
    "    # scale X so that each feature be between 0 and 1\n",
    "    X = MinMaxScaler().fit_transform(np.float32(X))\n",
    "    \n",
    "    return np.array(X, np.float16), np.array(y, np.uint8), lb.classes_\n",
    "\n",
    "\n",
    "# Using a trained model, calculate the F2_score\n",
    "# input: X_test, y_test, model\n",
    "# output: a list of F2_score by class(length 17)\n",
    "def calc_F2_score_cnn(X_test, y_test, model, thres = 0.2):\n",
    "    predicted = np.array(model.predict(X_test)) > thres\n",
    "    score = fbeta_score(y_test, predicted, beta=2, average=None)\n",
    "    return score\n",
    "\n",
    "def print_results(scores, ind_to_classes):\n",
    "    # print the scores with the classes\n",
    "    results = [(ind_to_classes[l], scores[l]) for l in scores.argsort()[::-1]]\n",
    "    print \"************************RESULTS************************\"\n",
    "    for res in results:\n",
    "        print res[0], res[1]\n",
    "    print \"************************END RESULTS************************\"\n",
    "    \n",
    "# define cross validation\n",
    "# if fold = 1 just use a 20% test set\n",
    "# Training model func: need to take in X_train, y_train, and initial model(if necessary)\n",
    "def cross_validation_train_score(X, y, train_model_func, scoring_func, folds=10):\n",
    "\n",
    "    if folds == 1:\n",
    "        print \"Using a 20% test set...\"\n",
    "        print \"X shape:\", X.shape\n",
    "        print \"y shape:\", y.shape\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "        model = train_model_func(X_train, y_train)\n",
    "        score = scoring_func(X_test, y_test, model)\n",
    "        return model, np.array(score)\n",
    "\n",
    "    print \"Using cross validation with folds\", folds\n",
    "    print \"X shape:\", X.shape\n",
    "    print \"y shape:\", y.shape    \n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    scores_all = []\n",
    "    for ind, (train, test) in enumerate(kf.split(X)):\n",
    "        print \"Fold \", ind\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "        model = train_model_func(X_train, y_train)\n",
    "        score = scoring_func(X_test, y_test, model)\n",
    "        scores_all.append(score)\n",
    "        \n",
    "    #TODO: change to return highest accurac model\n",
    "    return model, np.mean(np.array(scores_all), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN specific preprocessing function, creating 4 dimensional input vectors\n",
    "def preprocess_cnn(n_samples, rescaled_dim, f_path =\"../data/train.csv\"):\n",
    "    df = pd.read_csv(f_path)\n",
    "    df['split_tags'] = df['tags'].map(lambda row: row.split(\" \"))\n",
    "    lb = MultiLabelBinarizer()\n",
    "    y = lb.fit_transform(df['split_tags'])\n",
    "    y = y[:n_samples]\n",
    "    \n",
    "    imgs = []\n",
    "    # for each image, rescale to same dimension and flattern\n",
    "    print \"processing images...\"\n",
    "    count = 0\n",
    "    for name in df.head(n_samples)['image_name'].values:\n",
    "        raw_img = plt.imread('../data/train-jpg/{}.jpg'.format(name))\n",
    "        #print raw_img\n",
    "        imgs.append(cv2.resize(raw_img, (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR)[:, :, :3])\n",
    "        count+=1\n",
    "        if count % 1000 == 0:\n",
    "            print count, \"processed\"\n",
    "\n",
    "    # remove dimenions, normalize  \n",
    "    X = np.squeeze(np.array(imgs)) / 255.\n",
    "\n",
    "    return np.array(X, np.float16), np.array(y, np.uint8), lb.classes_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cnn_model_1(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(32, 32, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=64,\n",
    "              epochs=5,\n",
    "              verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing images...\n",
      "1000 processed\n",
      "2000 processed\n",
      "3000 processed\n",
      "4000 processed\n",
      "5000 processed\n",
      "6000 processed\n",
      "7000 processed\n",
      "8000 processed\n",
      "9000 processed\n",
      "10000 processed\n",
      "11000 processed\n",
      "12000 processed\n",
      "13000 processed\n",
      "14000 processed\n",
      "15000 processed\n",
      "16000 processed\n",
      "17000 processed\n",
      "18000 processed\n",
      "19000 processed\n",
      "20000 processed\n",
      "21000 processed\n",
      "22000 processed\n",
      "23000 processed\n",
      "24000 processed\n",
      "25000 processed\n",
      "26000 processed\n",
      "27000 processed\n",
      "28000 processed\n",
      "29000 processed\n",
      "30000 processed\n",
      "31000 processed\n",
      "32000 processed\n",
      "33000 processed\n",
      "34000 processed\n",
      "35000 processed\n",
      "36000 processed\n",
      "37000 processed\n",
      "38000 processed\n",
      "39000 processed\n",
      "40000 processed\n",
      "(40479, 32, 32, 3) (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 40482\n",
    "NUM_SAMPLE = NUM_TRAIN\n",
    "DIM = 32\n",
    "X, y, ind_to_classes = preprocess_cnn(NUM_SAMPLE, DIM, \"../data/train.csv\")\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a 20% test set...\n",
      "X shape: (40479, 32, 32, 3)\n",
      "y shape: (40479, 17)\n",
      "Epoch 1/5\n",
      "32383/32383 [==============================] - 78s - loss: 0.2342 - acc: 0.9103    \n",
      "Epoch 2/5\n",
      "32383/32383 [==============================] - 78s - loss: 0.1947 - acc: 0.9237    \n",
      "Epoch 3/5\n",
      "32383/32383 [==============================] - 78s - loss: 0.1844 - acc: 0.9280    \n",
      "Epoch 4/5\n",
      "32383/32383 [==============================] - 77s - loss: 0.1773 - acc: 0.9308    \n",
      "Epoch 5/5\n",
      "32383/32383 [==============================] - 79s - loss: 0.1708 - acc: 0.9336    \n",
      "************************RESULTS************************\n",
      "primary 0.987326887902\n",
      "clear 0.95884620587\n",
      "agriculture 0.812865085509\n",
      "partly_cloudy 0.787007318013\n",
      "road 0.73715675347\n",
      "cloudy 0.670297444491\n",
      "haze 0.609621740727\n",
      "water 0.604987684729\n",
      "habitation 0.571746384872\n",
      "cultivation 0.404491931967\n",
      "artisinal_mine 0.387409200969\n",
      "bare_ground 0.0298329355609\n",
      "slash_burn 0.0\n",
      "conventional_mine 0.0\n",
      "selective_logging 0.0\n",
      "blow_down 0.0\n",
      "blooming 0.0\n",
      "************************END RESULTS************************\n"
     ]
    }
   ],
   "source": [
    "model, cv_f2_scores = cross_validation_train_score(X, y, train_cnn_model_1, calc_F2_score_cnn, 1) #no cross-validation\n",
    "print_results(cv_f2_scores, ind_to_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "import datetime\n",
    "def timestamp():\n",
    "    return '{:%m%d_%H_%M_%s}'.format(datetime.datetime.now())\n",
    "\n",
    "fn = \"../data/cnn-1_\" + timestamp() + '.h5'\n",
    "model.save(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
